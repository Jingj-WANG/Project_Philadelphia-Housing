{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b7faca08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "import xgboost as xgb\n",
    "\n",
    "from sklearn.model_selection import PredefinedSplit, RandomizedSearchCV, KFold, StratifiedKFold\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "\n",
    "from scipy.stats import loguniform as sp_loguniform\n",
    "from scipy.stats import randint as sp_randint\n",
    "\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a84c31d",
   "metadata": {},
   "source": [
    "### Experiment on Single Family"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0a9df04d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get training, validation and test data for single family\n",
    "X_train_sf = pd.read_csv('X_train_sf.csv')\n",
    "X_train_sf.index = X_train_sf['Unnamed: 0']\n",
    "X_train_sf = X_train_sf.drop(['Unnamed: 0'], axis=1)\n",
    "X_val_sf = pd.read_csv('X_val_sf.csv')\n",
    "X_val_sf.index = X_val_sf['Unnamed: 0']\n",
    "X_val_sf = X_val_sf.drop(['Unnamed: 0'], axis=1)\n",
    "X_test_sf = pd.read_csv('X_test_sf.csv')\n",
    "X_test_sf.index = X_test_sf['Unnamed: 0']\n",
    "X_test_sf = X_test_sf.drop(['Unnamed: 0'], axis=1)\n",
    "y_train_sf = pd.read_csv('y_train_sf.csv')\n",
    "y_train_sf.index = y_train_sf['Unnamed: 0']\n",
    "y_train_sf = y_train_sf.drop(['Unnamed: 0'], axis=1)\n",
    "y_val_sf = pd.read_csv('y_val_sf.csv')\n",
    "y_val_sf.index = y_val_sf['Unnamed: 0']\n",
    "y_val_sf = y_val_sf.drop(['Unnamed: 0'], axis=1)\n",
    "y_test_sf = pd.read_csv('y_test_sf.csv')\n",
    "y_test_sf.index = y_test_sf['Unnamed: 0']\n",
    "y_test_sf = y_test_sf.drop(['Unnamed: 0'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f4682f9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a predefined validation set for random search\n",
    "y_train_plus_val_sf = pd.concat([y_train_sf, y_val_sf])\n",
    "y_train_plus_val_sf_copy = y_train_plus_val_sf.copy()\n",
    "y_train_plus_val_sf_copy.columns = ['train_val_split']\n",
    "y_train_plus_val_sf_copy.loc[y_train_sf.index,'train_val_split'] = -1\n",
    "y_train_plus_val_sf_copy.loc[y_val_sf.index,'train_val_split'] = 0\n",
    "val_fold_sf = np.array(y_train_plus_val_sf_copy)\n",
    "ps_sf = PredefinedSplit(val_fold_sf)\n",
    "\n",
    "# get training plus validation set\n",
    "X_train_plus_val_sf = pd.concat([X_train_sf, X_val_sf])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70e89724",
   "metadata": {},
   "source": [
    "### Single Family: Linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e6a0680a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'normalize': True, 'fit_intercept': False}\n",
      "LinearRegression(fit_intercept=False, normalize=True)\n",
      "Min RMSE for linear regression on Single Family is: 23479006242.85987\n"
     ]
    }
   ],
   "source": [
    "# random search for linear regression\n",
    "param_lr_sf = {'fit_intercept': [True,False],\n",
    "               'normalize':[True,False]}\n",
    "\n",
    "lr_cv_sf = RandomizedSearchCV(\n",
    "           LinearRegression(),\n",
    "           param_distributions=param_lr_sf,\n",
    "           n_iter=10,\n",
    "           cv=ps_sf,\n",
    "           scoring='neg_root_mean_squared_error', \n",
    "           n_jobs=-1,\n",
    "           random_state=123\n",
    ").fit(X_train_plus_val_sf, np.array(y_train_plus_val_sf).ravel())\n",
    "\n",
    "# find best model hyperparameters \n",
    "print(lr_cv_sf.best_params_)\n",
    "print(lr_cv_sf.best_estimator_)\n",
    "print('Min RMSE for linear regression on Single Family is: {}'.format(-lr_cv_sf.best_score_))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "454fa40f",
   "metadata": {},
   "source": [
    "### Single Family: Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e54ad8b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'alpha': 0.07684071705306554, 'fit_intercept': False, 'normalize': True}\n",
      "Lasso(alpha=0.07684071705306554, fit_intercept=False, normalize=True)\n",
      "Min RMSE for lasso on Single Family is: 237.02107253707626\n"
     ]
    }
   ],
   "source": [
    "# random search for lasso\n",
    "param_la_sf = {'alpha': sp_loguniform(1e-4,1e2),\n",
    "            'fit_intercept':[True,False],\n",
    "            'normalize':[True,False]}\n",
    "\n",
    "la_cv_sf = RandomizedSearchCV(\n",
    "        Lasso(),\n",
    "        param_distributions=param_la_sf,\n",
    "        n_iter=10,\n",
    "        cv=ps_sf,\n",
    "        scoring='neg_root_mean_squared_error', \n",
    "        n_jobs=-1,\n",
    "        random_state=123\n",
    ").fit(X_train_plus_val_sf, np.array(y_train_plus_val_sf).ravel())\n",
    "\n",
    "# find best model hyperparameters \n",
    "print(la_cv_sf.best_params_)\n",
    "print(la_cv_sf.best_estimator_)\n",
    "print('Min RMSE for lasso on Single Family is: {}'.format(-la_cv_sf.best_score_))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "528c6e3f",
   "metadata": {},
   "source": [
    "### Single Family: Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ab506be2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'alpha': 76.66289057556017, 'fit_intercept': True, 'normalize': False}\n",
      "Ridge(alpha=76.66289057556017)\n",
      "Min RMSE fort ridge on Single Family is: 236.94456670464658\n"
     ]
    }
   ],
   "source": [
    "# random search for ridge\n",
    "param_rd_sf = {'alpha': sp_loguniform(1e-4,1e2),\n",
    "            'fit_intercept':[True,False],\n",
    "            'normalize':[True,False]}\n",
    "\n",
    "rd_cv_sf = RandomizedSearchCV(\n",
    "        Ridge(),\n",
    "        param_distributions=param_rd_sf,\n",
    "        n_iter=10,\n",
    "        cv=ps_sf,\n",
    "        scoring='neg_root_mean_squared_error', \n",
    "        n_jobs=-1,\n",
    "        random_state=123\n",
    ").fit(X_train_plus_val_sf, np.array(y_train_plus_val_sf).ravel())\n",
    "\n",
    "# Find best model hyperparameters \n",
    "print(rd_cv_sf.best_params_)\n",
    "print(rd_cv_sf.best_estimator_)\n",
    "print('Min RMSE fort ridge on Single Family is: {}'.format(-rd_cv_sf.best_score_))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fb13e99",
   "metadata": {},
   "source": [
    "### Single Family: KNeighborsRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e8ab1b1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'leaf_size': 5, 'n_neighbors': 18, 'weights': 'distance'}\n",
      "KNeighborsRegressor(leaf_size=5, n_neighbors=18, weights='distance')\n",
      "Min RMSE for Knn regressor on Single Family is: 170.7286967851921\n"
     ]
    }
   ],
   "source": [
    "# random search for KNeighborsRegressor\n",
    "param_knn_sf = {'n_neighbors': sp_randint(1,21),\n",
    "             'weights': ['uniform', 'distance'],\n",
    "             'leaf_size': sp_randint(1,21)}\n",
    "\n",
    "knn_cv_sf = RandomizedSearchCV(\n",
    "         KNeighborsRegressor(),\n",
    "         param_distributions=param_knn_sf,\n",
    "         n_iter=10,\n",
    "         cv=ps_sf,\n",
    "         scoring='neg_root_mean_squared_error', \n",
    "         n_jobs=-1,\n",
    "         random_state=123\n",
    ").fit(X_train_plus_val_sf, np.array(y_train_plus_val_sf).ravel())\n",
    "\n",
    "# find best model hyperparameters \n",
    "print(knn_cv_sf.best_params_)\n",
    "print(knn_cv_sf.best_estimator_)\n",
    "print('Min RMSE for Knn regressor on Single Family is: {}'.format(-knn_cv_sf.best_score_))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e736c9f0",
   "metadata": {},
   "source": [
    "### Single Family: RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bc0c451d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_estimators': 800, 'min_samples_split': 2, 'min_samples_leaf': 5, 'max_features': 'auto', 'max_depth': None}\n",
      "RandomForestRegressor(min_samples_leaf=5, n_estimators=800)\n",
      "Min RMSE is for random forest regressor on Single Family is: 137.07311863070748\n"
     ]
    }
   ],
   "source": [
    "# random search for RandomForestRegressor\n",
    "param_rf_sf = {'n_estimators': [100, 120, 200, 300, 500, 800, 1200],\n",
    "            'max_depth': [None, 5, 8, 15, 25, 30],\n",
    "            'min_samples_split': [1, 2, 5, 10 ,15, 100],\n",
    "            'min_samples_leaf': [1, 2, 5, 10],\n",
    "            'max_features': ['auto', 'sqrt', 'log2']}\n",
    "\n",
    "rf_cv_sf = RandomizedSearchCV(\n",
    "        RandomForestRegressor(),\n",
    "        param_distributions=param_rf_sf,\n",
    "        n_iter=10,\n",
    "        cv=ps_sf,\n",
    "        scoring='neg_root_mean_squared_error', \n",
    "        n_jobs=-1,\n",
    "        random_state=123\n",
    ").fit(X_train_plus_val_sf, np.array(y_train_plus_val_sf).ravel())\n",
    "\n",
    "# find best model hyperparameters \n",
    "print(rf_cv_sf.best_params_)\n",
    "print(rf_cv_sf.best_estimator_)\n",
    "print('Min RMSE is for random forest regressor on Single Family is: {}'.format(-rf_cv_sf.best_score_))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e04ff10",
   "metadata": {},
   "source": [
    "### Single Family: MLPRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a09dd3eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'alpha': 0.0011051954732269518, 'batch_size': 100, 'hidden_layer_sizes': (15, 15), 'learning_rate_init': 0.0002900807334178909}\n",
      "MLPRegressor(alpha=0.0011051954732269518, batch_size=100,\n",
      "             hidden_layer_sizes=(15, 15),\n",
      "             learning_rate_init=0.0002900807334178909)\n",
      "Min RMSE for MLP regressor on Single Family is: 197.56949111841487\n"
     ]
    }
   ],
   "source": [
    "# random search for MLPRegressor\n",
    "hl = []\n",
    "for i in [1, 2, 3, 4, 5, 10, 15, 25, 30]:\n",
    "    hl.append((i))\n",
    "    hl.append((i,i))\n",
    "\n",
    "param_mlp_sf = {'hidden_layer_sizes': hl,\n",
    "             'learning_rate_init': sp_loguniform(1e-4, 1e2),\n",
    "             'alpha': sp_loguniform(1e-4, 1e2),\n",
    "             'batch_size': [1, 3, 5, 10, 20, 50, 100, 250, 500]}\n",
    "\n",
    "mlp_cv_sf = RandomizedSearchCV(\n",
    "         MLPRegressor(),\n",
    "         param_distributions=param_mlp_sf,\n",
    "         n_iter=10,\n",
    "         cv=ps_sf,\n",
    "         scoring='neg_root_mean_squared_error', \n",
    "         n_jobs=-1,\n",
    "         random_state=123\n",
    ").fit(X_train_plus_val_sf, np.array(y_train_plus_val_sf).ravel())\n",
    "\n",
    "# find best model hyperparameters \n",
    "print(mlp_cv_sf.best_params_)\n",
    "print(mlp_cv_sf.best_estimator_)\n",
    "print('Min RMSE for MLP regressor on Single Family is: {}'.format(-mlp_cv_sf.best_score_))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db8db376",
   "metadata": {},
   "source": [
    "### Single Family: XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ffe97633",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10:51:57] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: \n",
      "Parameters: { \"learning_rate_init\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "{'learning_rate_init': 0.15522637752063606, 'max_depth': 11, 'min_child_weight': 3, 'n_estimators': 100}\n",
      "XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "             colsample_bynode=1, colsample_bytree=1, enable_categorical=False,\n",
      "             gamma=0, gpu_id=-1, importance_type=None,\n",
      "             interaction_constraints='', learning_rate=0.300000012,\n",
      "             learning_rate_init=0.15522637752063606, max_delta_step=0,\n",
      "             max_depth=11, min_child_weight=3, missing=nan,\n",
      "             monotone_constraints='()', n_estimators=100, n_jobs=16, nthread=-1,\n",
      "             num_parallel_tree=1, predictor='auto', random_state=0, reg_alpha=0,\n",
      "             reg_lambda=1, scale_pos_weight=1, subsample=1, tree_method='exact',\n",
      "             validate_parameters=1, verbosity=None)\n",
      "Min RMSE for XGBoost on Single Family is: 131.88880629549743\n"
     ]
    }
   ],
   "source": [
    "# random search for XGBoost\n",
    "param_xg_sf = {'n_estimators':[100, 500 ,1000],\n",
    "               'max_depth': sp_randint(3, 15),\n",
    "               'learning_rate_init': sp_loguniform(1e-4, 1e2),\n",
    "               'min_child_weight': [1, 3, 5, 7]}\n",
    "\n",
    "xg_cv_sf = RandomizedSearchCV(\n",
    "            xgb.XGBRegressor(nthread=-1),\n",
    "            param_distributions=param_xg_sf,\n",
    "            n_iter=10,\n",
    "            cv=ps_sf,\n",
    "            scoring='neg_root_mean_squared_error',\n",
    "            n_jobs=-1,\n",
    "            random_state=123\n",
    ").fit(X_train_plus_val_sf, np.array(y_train_plus_val_sf).ravel())\n",
    "\n",
    "# find best model hyperparameters \n",
    "print(xg_cv_sf.best_params_)\n",
    "print(xg_cv_sf.best_estimator_)\n",
    "print('Min RMSE for XGBoost on Single Family is: {}'.format(-xg_cv_sf.best_score_))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c89d66a6",
   "metadata": {},
   "source": [
    "### Experiment on Mixed Use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "55dae339",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get training, validation and test data for mixed use\n",
    "X_train_mx = pd.read_csv('X_train_mx.csv')\n",
    "X_train_mx.index = X_train_mx['Unnamed: 0']\n",
    "X_train_mx = X_train_mx.drop(['Unnamed: 0'], axis=1)\n",
    "X_val_mx = pd.read_csv('X_val_mx.csv')\n",
    "X_val_mx.index = X_val_mx['Unnamed: 0']\n",
    "X_val_mx = X_val_mx.drop(['Unnamed: 0'], axis=1)\n",
    "X_test_mx = pd.read_csv('X_test_mx.csv')\n",
    "X_test_mx.index = X_test_mx['Unnamed: 0']\n",
    "X_test_mx = X_test_mx.drop(['Unnamed: 0'], axis=1)\n",
    "y_train_mx = pd.read_csv('y_train_mx.csv')\n",
    "y_train_mx.index = y_train_mx['Unnamed: 0']\n",
    "y_train_mx = y_train_mx.drop(['Unnamed: 0'], axis=1)\n",
    "y_val_mx = pd.read_csv('y_val_mx.csv')\n",
    "y_val_mx.index = y_val_mx['Unnamed: 0']\n",
    "y_val_mx = y_val_mx.drop(['Unnamed: 0'], axis=1)\n",
    "y_test_mx = pd.read_csv('y_test_mx.csv')\n",
    "y_test_mx.index = y_test_mx['Unnamed: 0']\n",
    "y_test_mx = y_test_mx.drop(['Unnamed: 0'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fa856a4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get training plus validation set\n",
    "X_train_plus_val_mx = pd.concat([X_train_mx, X_val_mx])\n",
    "y_train_plus_val_mx = pd.concat([y_train_mx, y_val_mx])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "927bf064",
   "metadata": {},
   "source": [
    "### Mixed Use: Linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a26e4141",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'normalize': True, 'fit_intercept': False}\n",
      "LinearRegression(fit_intercept=False, normalize=True)\n",
      "Min RMSE for linear regression is: 10122191127754.484\n"
     ]
    }
   ],
   "source": [
    "# random search for linear regression\n",
    "param_lr_mx = {'fit_intercept': [True,False],\n",
    "               'normalize':[True,False]}\n",
    "\n",
    "lr_cv_mx = RandomizedSearchCV(\n",
    "           LinearRegression(),\n",
    "           param_distributions=param_lr_mx,\n",
    "           n_iter=10,\n",
    "           cv=5,\n",
    "           scoring='neg_root_mean_squared_error', \n",
    "           n_jobs=-1,\n",
    "           random_state=123\n",
    ").fit(X_train_plus_val_mx, np.array(y_train_plus_val_mx).ravel())\n",
    "\n",
    "# find best model hyperparameters \n",
    "print(lr_cv_mx.best_params_)\n",
    "print(lr_cv_mx.best_estimator_)\n",
    "print('Min RMSE for linear regression is: {}'.format(-lr_cv_mx.best_score_))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d84e511",
   "metadata": {},
   "source": [
    "### Mixed Use: Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "104076e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'alpha': 0.15463515822289586, 'fit_intercept': True, 'normalize': False}\n",
      "Lasso(alpha=0.15463515822289586)\n",
      "Min RMSE for lasso fro Mixed Use is: 261.77672139034263\n"
     ]
    }
   ],
   "source": [
    "# random search for lasso\n",
    "param_la_mx = {'alpha': sp_loguniform(1e-4,1e2),\n",
    "            'fit_intercept':[True,False],\n",
    "            'normalize':[True,False]}\n",
    "\n",
    "la_cv_mx = RandomizedSearchCV(\n",
    "        Lasso(),\n",
    "        param_distributions=param_la_mx,\n",
    "        n_iter=10,\n",
    "        cv=5,\n",
    "        scoring='neg_root_mean_squared_error', \n",
    "        n_jobs=-1,\n",
    "        random_state=123\n",
    ").fit(X_train_plus_val_mx, np.array(y_train_plus_val_mx).ravel())\n",
    "\n",
    "# find best model hyperparameters \n",
    "print(la_cv_mx.best_params_)\n",
    "print(la_cv_mx.best_estimator_)\n",
    "print('Min RMSE for lasso fro Mixed Use is: {}'.format(-la_cv_mx.best_score_))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59c2b737",
   "metadata": {},
   "source": [
    "### Mixed Use: Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "10519400",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'alpha': 76.66289057556017, 'fit_intercept': True, 'normalize': False}\n",
      "Ridge(alpha=76.66289057556017)\n",
      "Min RMSE for ridge on Mixed Use is: 261.77449765235895\n"
     ]
    }
   ],
   "source": [
    "# random search for ridge\n",
    "param_rd_mx = {'alpha': sp_loguniform(1e-4,1e2),\n",
    "            'fit_intercept':[True,False],\n",
    "            'normalize':[True,False]}\n",
    "\n",
    "rd_cv_mx = RandomizedSearchCV(\n",
    "        Ridge(),\n",
    "        param_distributions=param_rd_mx,\n",
    "        n_iter=10,\n",
    "        cv=5,\n",
    "        scoring='neg_root_mean_squared_error', \n",
    "        n_jobs=-1,\n",
    "        random_state=123\n",
    ").fit(X_train_plus_val_mx, np.array(y_train_plus_val_mx).ravel())\n",
    "\n",
    "# Find best model hyperparameters \n",
    "print(rd_cv_mx.best_params_)\n",
    "print(rd_cv_mx.best_estimator_)\n",
    "print('Min RMSE for ridge on Mixed Use is: {}'.format(-rd_cv_mx.best_score_))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "790337d3",
   "metadata": {},
   "source": [
    "### Mixed Use: KNeighborsRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "631420e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'leaf_size': 20, 'n_neighbors': 11, 'weights': 'distance'}\n",
      "KNeighborsRegressor(leaf_size=20, n_neighbors=11, weights='distance')\n",
      "Min RMSE for Knn regressor on Mixed Use is: 240.56197162525683\n"
     ]
    }
   ],
   "source": [
    "# random search for KNeighborsRegressor\n",
    "param_knn_mx = {'n_neighbors': sp_randint(1,21),\n",
    "             'weights': ['uniform', 'distance'],\n",
    "             'leaf_size': sp_randint(1,21)}\n",
    "\n",
    "knn_cv_mx = RandomizedSearchCV(\n",
    "         KNeighborsRegressor(),\n",
    "         param_distributions=param_knn_mx,\n",
    "         n_iter=10,\n",
    "         cv=5,\n",
    "         scoring='neg_root_mean_squared_error', \n",
    "         n_jobs=-1,\n",
    "         random_state=123\n",
    ").fit(X_train_plus_val_mx, np.array(y_train_plus_val_mx).ravel())\n",
    "\n",
    "# find best model hyperparameters \n",
    "print(knn_cv_mx.best_params_)\n",
    "print(knn_cv_mx.best_estimator_)\n",
    "print('Min RMSE for Knn regressor on Mixed Use is: {}'.format(-knn_cv_mx.best_score_))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49ddb9b9",
   "metadata": {},
   "source": [
    "### Mixed Use: RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ffd72c50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_estimators': 800, 'min_samples_split': 2, 'min_samples_leaf': 5, 'max_features': 'auto', 'max_depth': None}\n",
      "RandomForestRegressor(min_samples_leaf=5, n_estimators=800)\n",
      "Min RMSE is for random forest regressor on Mixed Use is: 207.89628200007058\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# random search for RandomForestRegressor\n",
    "param_rf_mx = {'n_estimators': [100, 120, 200, 300, 500, 800, 1200],\n",
    "            'max_depth': [None, 5, 8, 15, 25, 30],\n",
    "            'min_samples_split': [1, 2, 5, 10 ,15, 100],\n",
    "            'min_samples_leaf': [1, 2, 5, 10],\n",
    "            'max_features': ['auto', 'sqrt', 'log2']}\n",
    "\n",
    "rf_cv_mx = RandomizedSearchCV(\n",
    "        RandomForestRegressor(),\n",
    "        param_distributions=param_rf_mx,\n",
    "        n_iter=10,\n",
    "        cv=5,\n",
    "        scoring='neg_root_mean_squared_error', \n",
    "        n_jobs=-1,\n",
    "        random_state=123\n",
    ").fit(X_train_plus_val_mx, np.array(y_train_plus_val_mx).ravel())\n",
    "\n",
    "# find best model hyperparameters \n",
    "print(rf_cv_mx.best_params_)\n",
    "print(rf_cv_mx.best_estimator_)\n",
    "print('Min RMSE is for random forest regressor on Mixed Use is: {}'.format(-rf_cv_mx.best_score_))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14668a69",
   "metadata": {},
   "source": [
    "### Mixed Use: MLPRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8ac92283",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'alpha': 2.765529811671396, 'batch_size': 20, 'hidden_layer_sizes': 4, 'learning_rate_init': 0.008664699052148592}\n",
      "MLPRegressor(alpha=2.765529811671396, batch_size=20, hidden_layer_sizes=4,\n",
      "             learning_rate_init=0.008664699052148592)\n",
      "Min RMSE for MLP regressor on Mixed Use is: 237.07285795891545\n"
     ]
    }
   ],
   "source": [
    "# random search for MLPRegressor\n",
    "hl = []\n",
    "for i in [1, 2, 3, 4, 5, 10, 15, 25, 30]:\n",
    "    hl.append((i))\n",
    "    hl.append((i,i))\n",
    "\n",
    "param_mlp_mx = {'hidden_layer_sizes': hl,\n",
    "             'learning_rate_init': sp_loguniform(1e-4, 1e2),\n",
    "             'alpha': sp_loguniform(1e-4, 1e2),\n",
    "             'batch_size': [1, 3, 5, 10, 20, 50, 100, 250, 500]}\n",
    "\n",
    "mlp_cv_mx = RandomizedSearchCV(\n",
    "         MLPRegressor(),\n",
    "         param_distributions=param_mlp_mx,\n",
    "         n_iter=10,\n",
    "         cv=5,\n",
    "         scoring='neg_root_mean_squared_error', \n",
    "         n_jobs=-1,\n",
    "         random_state=123\n",
    ").fit(X_train_plus_val_mx, np.array(y_train_plus_val_mx).ravel())\n",
    "\n",
    "# find best model hyperparameters \n",
    "print(mlp_cv_mx.best_params_)\n",
    "print(mlp_cv_mx.best_estimator_)\n",
    "print('Min RMSE for MLP regressor on Mixed Use is: {}'.format(-mlp_cv_mx.best_score_))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64c0ebb4",
   "metadata": {},
   "source": [
    "### Mixed Use: XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "99e829bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10:57:27] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: \n",
      "Parameters: { \"learning_rate_init\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "{'learning_rate_init': 0.20318358298265976, 'max_depth': 6, 'min_child_weight': 5, 'n_estimators': 500}\n",
      "XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "             colsample_bynode=1, colsample_bytree=1, enable_categorical=False,\n",
      "             gamma=0, gpu_id=-1, importance_type=None,\n",
      "             interaction_constraints='', learning_rate=0.300000012,\n",
      "             learning_rate_init=0.20318358298265976, max_delta_step=0,\n",
      "             max_depth=6, min_child_weight=5, missing=nan,\n",
      "             monotone_constraints='()', n_estimators=500, n_jobs=16, nthread=-1,\n",
      "             num_parallel_tree=1, predictor='auto', random_state=0, reg_alpha=0,\n",
      "             reg_lambda=1, scale_pos_weight=1, subsample=1, tree_method='exact',\n",
      "             validate_parameters=1, verbosity=None)\n",
      "Min RMSE for XGBoost on Mixed Use is: 213.94762819826306\n"
     ]
    }
   ],
   "source": [
    "# random search for XGBoost\n",
    "param_xg_mx = {'n_estimators':[100, 500 ,1000],\n",
    "               'max_depth': sp_randint(3, 15),\n",
    "               'learning_rate_init': sp_loguniform(1e-4, 1e2),\n",
    "               'min_child_weight': [1, 3, 5, 7]}\n",
    "\n",
    "xg_cv_mx = RandomizedSearchCV(\n",
    "            xgb.XGBRegressor(nthread=-1),\n",
    "            param_distributions=param_xg_mx,\n",
    "            n_iter=10,\n",
    "            cv=5,\n",
    "            scoring='neg_root_mean_squared_error',\n",
    "            n_jobs=-1,\n",
    "            random_state=123\n",
    ").fit(X_train_plus_val_mx, np.array(y_train_plus_val_mx).ravel())\n",
    "\n",
    "# find best model hyperparameters \n",
    "print(xg_cv_mx.best_params_)\n",
    "print(xg_cv_mx.best_estimator_)\n",
    "print('Min RMSE for XGBoost on Mixed Use is: {}'.format(-xg_cv_mx.best_score_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4762d999",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f9fdb0a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
