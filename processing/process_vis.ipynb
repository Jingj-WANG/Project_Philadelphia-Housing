{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import statements\n",
    "import pandas as pd \n",
    "import numpy as np \n",
    "import pickle\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read in data   \n",
    "Read in those properties that fall under \"Multi Family\" and \"Single Family\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Find the data codebook here**:   https://metadata.phila.gov/#home/datasetdetails/5543865f20583086178c4ee5/representationdetails/55d624fdad35c7e854cb21a4/?view_287_page=1\n",
    "\n",
    "**Columns to keep**:  'assessment_date', 'basements', 'building_code_description',\n",
    "                 'category_code_description','census_tract', 'central_air','depth',\n",
    "                 'exterior_condition', 'fireplaces', 'frontage', 'fuel', 'garage_spaces',\n",
    "                 'geographic_ward', 'house_number', \n",
    "                 'interior_condition',\n",
    "                 'market_value', 'market_value_date', 'number_of_bathrooms', \n",
    "                 'number_of_bedrooms', 'number_of_rooms','number_stories', 'quality_grade', \n",
    "                 'sale_date', 'sale_price', 'street_designation',\n",
    "                 'topography', 'total_area','total_livable_area', 'type_heater', \n",
    "                 'unfinished',  'view_type', 'year_built',\n",
    "                 'zip_code',  'lat', 'lng'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [],
   "source": [
    "#place columns of interest into a list\n",
    "cols_interest = ['assessment_date', 'basements', \n",
    "                 'category_code_description','census_tract', 'central_air','depth',\n",
    "                 'exterior_condition', 'fireplaces', 'frontage', 'fuel', 'garage_spaces',\n",
    "                 'geographic_ward', 'house_number', \n",
    "                 'interior_condition',\n",
    "                 'market_value', 'market_value_date', 'number_of_bathrooms', \n",
    "                 'number_of_bedrooms', 'number_of_rooms','number_stories', 'quality_grade', \n",
    "                 'sale_date', 'sale_price', 'street_designation',\n",
    "                 'topography', 'total_area','total_livable_area', 'type_heater', \n",
    "                 'unfinished',  'view_type', 'year_built',\n",
    "                 'zip_code',  'lat', 'lng']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3146: DtypeWarning: Columns (67,71) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "#read in data using columns of interest \n",
    "#query only those multifamily and single family homes\n",
    "dat = (pd.read_csv(\"/home/jovyan/work/Philadelphia-Housing/processing/opa_properties_public.csv\", \n",
    "                 usecols = cols_interest)\n",
    "       .query('category_code_description == \"Multi Family\" | category_code_description == \"Single Family\"')\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We re-code four columns of interest (basements, central_air, fuel, topography, type_heater, street_designation).    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ST      371811\n",
       "AVE      73019\n",
       "RD       29498\n",
       "LA        7600\n",
       "DR        5777\n",
       "PL        5651\n",
       "SQ        2369\n",
       "BLV       2212\n",
       "TER       1595\n",
       "CT        1135\n",
       "WAY       1065\n",
       "CIR        776\n",
       "LN         569\n",
       "PK         497\n",
       "PKY        344\n",
       "PLZ        168\n",
       "BLVD       126\n",
       "MEW         79\n",
       "ALY         59\n",
       "WLK         55\n",
       "PIKE        29\n",
       "HTS         22\n",
       "PTH         12\n",
       "PKWY         9\n",
       "MEWS         7\n",
       "WALK         5\n",
       "ROW          4\n",
       "PATH         3\n",
       "ML           3\n",
       "MALL         1\n",
       "Name: street_designation, dtype: int64"
      ]
     },
     "execution_count": 311,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat['street_designation'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat['basements'] = dat['basements'].map({'A': 'full', 'B': 'full','C': 'full','D': 'full','I': 'full',\n",
    "                                        'E': 'partial','F': 'partial','G': 'partial','H': 'partial','J': 'partial',\n",
    "                                        '0': 'None'})\n",
    "dat['central_air'] = dat['central_air'].map({'0': 'N', '1': 'Y','Y': 'Y', 'N': 'N'})\n",
    "\n",
    "dat['fuel'] = dat['fuel'].map({'A': 'NG', 'B': 'Oil','C': 'Electric',\n",
    "                              'E': 'other', 'G': 'other','H': 'other','I':'other'})\n",
    "dat['topography'] = dat['topography'].map({'A': 'A', 'B': 'B','C': 'C',\n",
    "                              'D': 'D', 'E': 'E','F': 'F'})\n",
    "\n",
    "dat['type_heater'] = dat['type_heater'].map({'A': 'A', 'B': 'B','C': 'C',\n",
    "                              'D': 'D', 'E': 'E','G': 'G','H': 'H'})\n",
    "\n",
    "dat['street_designation'] = dat['street_designation'].astype(\"string\")\n",
    "\n",
    "dat['street_designation'] = np.where(dat['street_designation'].str.match(\"ST\"), \"ST\",\n",
    "                                  np.where(dat['street_designation'].str.match(\"AVE\"), \"AVE\",\n",
    "                                  np.where(dat['street_designation'].str.match(\"RD\"), \"RD\",\n",
    "                                  np.where(dat['street_designation'].str.match(\"LA\"), \"LA\",\n",
    "                                  np.where(dat['street_designation'].str.match(\"DR\"), \"DR\",\n",
    "                                  np.where(dat['street_designation'].str.match(\"PL\"), \"PL\",\n",
    "                                  np.where(dat['street_designation'].str.match(\"SQ\"), \"SQ\",\"Other\")))))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below, we output the percentage missing by column:  \n",
    "Note that assessment_date, fuel, market_value_date, quality_grade, and unfinished are all over ~90% missing.   \n",
    "For these reasons, we will drop these columns from the analysis, as they will not provide robust and useful information for the analysis and prediction process.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "assessment_date               93.949851\n",
       "basements                     36.815857\n",
       "category_code_description      0.000000\n",
       "census_tract                   0.006938\n",
       "central_air                   44.558375\n",
       "depth                          0.077899\n",
       "exterior_condition             0.088206\n",
       "fireplaces                     0.164718\n",
       "frontage                       0.079088\n",
       "fuel                          97.111992\n",
       "garage_spaces                  0.199405\n",
       "geographic_ward                0.006938\n",
       "house_number                   0.000000\n",
       "interior_condition             0.109812\n",
       "market_value                   0.018236\n",
       "market_value_date            100.000000\n",
       "number_of_bathrooms            0.143707\n",
       "number_of_bedrooms             0.083845\n",
       "number_of_rooms                5.908622\n",
       "number_stories                 0.083251\n",
       "quality_grade                 89.448167\n",
       "sale_date                      0.001586\n",
       "sale_price                     0.002180\n",
       "street_designation             0.000000\n",
       "topography                     6.621011\n",
       "total_area                     0.047572\n",
       "total_livable_area             0.038454\n",
       "type_heater                   43.646581\n",
       "unfinished                    99.647175\n",
       "view_type                      0.446977\n",
       "year_built                     0.038454\n",
       "zip_code                       0.006739\n",
       "lat                            0.006739\n",
       "lng                            0.006739\n",
       "dtype: float64"
      ]
     },
     "execution_count": 313,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat.isnull().sum() * 100 / len(dat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat = dat.drop(['assessment_date', 'fuel', \n",
    "         'market_value_date', 'quality_grade', \n",
    "         'unfinished', 'central_air', 'type_heater'], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will remove those datapoints/rows that do not have values for **sale price** or **sale date**.   \n",
    "These are removed since these are our outcome variables.  \n",
    "Both the sales prices and the date which the house was sold is necessary to perform our experiment.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop the rows which 'sale_date' is NAN\n",
    "dat = dat[dat['sale_date'].notna()]\n",
    "#drop the rows which 'sale_price' is NAN\n",
    "dat = dat[dat['sale_price'].notna()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find the percentage of homes that have a sales price of greater than \\\\$5 million "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2820675971131184"
      ]
     },
     "execution_count": 316,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(dat['sale_price'] > 5_000_000).mean() *100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Note*: 0.28% of the data has a sale_price of greater than \\\\$5 million.   \n",
    "We remove these from the dataset since we are not interested in these homes.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat = dat[dat['sale_price'] < 5_000_000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find the percentage of homes that have a sales price of $1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26.218538846734162"
      ]
     },
     "execution_count": 318,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(dat['sale_price'] == 1).mean() *100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28.612975880693618"
      ]
     },
     "execution_count": 326,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(dat['sale_price']  < 1000).mean() *100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: 26% of the data has a sale_price of \\\\$1.   \n",
    "Further, 28.6 of the data has a sales price of \\\\$1000.   \n",
    "We remove these from the dataset since we believe these sales prices were not indicative of true sales.   \n",
    "We are also not interested in those homes sold for \\\\$1.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat = dat[dat['sale_price'] > 1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    3.582260e+05\n",
       "mean     1.693408e+05\n",
       "std      2.913644e+05\n",
       "min      1.001000e+03\n",
       "25%      4.100000e+04\n",
       "50%      9.500000e+04\n",
       "75%      1.950000e+05\n",
       "max      4.998000e+06\n",
       "Name: sale_price, dtype: float64"
      ]
     },
     "execution_count": 328,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat['sale_price'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we deal with dates:    \n",
    "First we coerce the dates    \n",
    "Next we will break apart the date elements into variables   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a date variable\n",
    "dat['sale_date'] = pd.to_datetime(dat['sale_date'])\n",
    "#break apart the date to new variables:  \n",
    "dat['sale_year'] = dat['sale_date'].dt.year\n",
    "dat['sale_month'] = dat['sale_date'].dt.month\n",
    "dat['sale_week'] = dat['sale_date'].dt.isocalendar().week\n",
    "dat['sale_day'] = dat['sale_date'].dt.day\n",
    "dat['sale_dow'] = dat['sale_date'].dt.dayofweek\n",
    "#change the sale week column type to int since it is coerced originally to \n",
    "#UInt32\n",
    "dat['sale_week'] = dat['sale_week'].astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Certain 'year_built' inputs are incorrect.    \n",
    "We ensure to change these below:   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat['year_built'] = dat['year_built'].replace('196Y', np.NaN)\n",
    "#convert to numeric\n",
    "dat[\"year_built\"] = pd.to_numeric(dat[\"year_built\"])\n",
    "#replace year 0 with NaN\n",
    "dat['year_built'] = dat['year_built'].replace(0, np.NaN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    357830.000000\n",
       "mean       1938.207068\n",
       "std          28.615644\n",
       "min        1652.000000\n",
       "25%        1920.000000\n",
       "50%        1928.000000\n",
       "75%        1952.000000\n",
       "max        2022.000000\n",
       "Name: year_built, dtype: float64"
      ]
     },
     "execution_count": 331,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat['year_built'].describe(include = 'all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.11054473991279248"
      ]
     },
     "execution_count": 332,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat['year_built'].isnull().sum() * 100 / len(dat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now perform preliminary train/test processing of the data necessary for modeling    \n",
    "\n",
    "### Training / Test Split\n",
    "\n",
    "First, we will split the data into training and test sets:   \n",
    "The training dataset contains all housing prices that were sold during the years of 2010 - 2019.    \n",
    "The test dataset contains all housing prices that were sold during 2020 and 2021.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [],
   "source": [
    "#first subset the data only to 2010 - 2021\n",
    "dat = dat[dat['sale_year'] > 2009]\n",
    "#split to the training set \n",
    "train = dat[dat['sale_year'] < 2020]\n",
    "#split to the test set \n",
    "test = dat[dat['sale_year'] > 2019]\n",
    "\n",
    "#finally, drop the date column:  \n",
    "train = train.drop(['sale_date'], axis=1)\n",
    "test = test.drop(['sale_date'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(150594, 31)"
      ]
     },
     "execution_count": 334,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(29614, 31)"
      ]
     },
     "execution_count": 335,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8356676729113025"
      ]
     },
     "execution_count": 336,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape[0] / (train.shape[0] + test.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The training data represents approximately 84% of the entire data.   \n",
    "The test data represents 26%   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We pickle the training data that has not yet been processed for visualization purposes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle_out = open(\"housedat_train_vis.pickle\",\"wb\")\n",
    "pickle.dump(train, pickle_out)\n",
    "pickle_out.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Processing part 2\n",
    "Next, we process the training data via one hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert categorical variables to dummy variables and add dummy variables to data frame\n",
    "cat_vars = train[['basements','category_code_description','street_designation',\n",
    "               'topography', 'view_type']]\n",
    "cat_dummies = pd.get_dummies(cat_vars, drop_first=True)\n",
    "train = train.drop(['basements','category_code_description','street_designation',\n",
    "               'topography', 'view_type'], axis=1)\n",
    "train = pd.concat([train, cat_dummies], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.fillna(train.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.29815987514127607"
      ]
     },
     "execution_count": 340,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "reg = LinearRegression().fit(train.drop(['sale_price'], axis=1),\n",
    "           train['sale_price'])\n",
    "reg.score(train.drop(['sale_price'], axis=1),\n",
    "           train['sale_price'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>       <td>sale_price</td>    <th>  R-squared (uncentered):</th>       <td>   0.511</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared (uncentered):</th>  <td>   0.511</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th>           <td>   3347.</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Thu, 07 Apr 2022</td> <th>  Prob (F-statistic):</th>            <td>  0.00</td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>02:25:03</td>     <th>  Log-Likelihood:    </th>          <td>-2.1030e+06</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>150594</td>      <th>  AIC:               </th>           <td>4.206e+06</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>150547</td>      <th>  BIC:               </th>           <td>4.206e+06</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>    47</td>      <th>                     </th>               <td> </td>     \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>               <td> </td>     \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "                     <td></td>                        <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>census_tract</th>                            <td> -542.0122</td> <td>   12.460</td> <td>  -43.501</td> <td> 0.000</td> <td> -566.433</td> <td> -517.591</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>depth</th>                                   <td>    2.2588</td> <td>    1.652</td> <td>    1.367</td> <td> 0.171</td> <td>   -0.979</td> <td>    5.496</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>exterior_condition</th>                      <td> -1.33e+04</td> <td> 3855.868</td> <td>   -3.449</td> <td> 0.001</td> <td>-2.09e+04</td> <td>-5739.806</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>fireplaces</th>                              <td> 1.307e+05</td> <td> 2687.158</td> <td>   48.628</td> <td> 0.000</td> <td> 1.25e+05</td> <td> 1.36e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>frontage</th>                                <td>    0.3336</td> <td>    0.063</td> <td>    5.330</td> <td> 0.000</td> <td>    0.211</td> <td>    0.456</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>garage_spaces</th>                           <td> 2.035e+04</td> <td>  960.676</td> <td>   21.186</td> <td> 0.000</td> <td> 1.85e+04</td> <td> 2.22e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>geographic_ward</th>                         <td>-1241.4575</td> <td>   49.592</td> <td>  -25.034</td> <td> 0.000</td> <td>-1338.656</td> <td>-1144.259</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>house_number</th>                            <td>   -3.3164</td> <td>    0.256</td> <td>  -12.973</td> <td> 0.000</td> <td>   -3.818</td> <td>   -2.815</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>interior_condition</th>                      <td>-4.874e+04</td> <td> 3831.887</td> <td>  -12.720</td> <td> 0.000</td> <td>-5.63e+04</td> <td>-4.12e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>market_value</th>                            <td>    0.1034</td> <td>    0.001</td> <td>   78.353</td> <td> 0.000</td> <td>    0.101</td> <td>    0.106</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>number_of_bathrooms</th>                     <td> 3.125e+04</td> <td> 1270.482</td> <td>   24.599</td> <td> 0.000</td> <td> 2.88e+04</td> <td> 3.37e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>number_of_bedrooms</th>                      <td>-7195.0285</td> <td>  821.403</td> <td>   -8.759</td> <td> 0.000</td> <td>-8804.962</td> <td>-5585.095</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>number_of_rooms</th>                         <td>-8326.5364</td> <td>  392.414</td> <td>  -21.219</td> <td> 0.000</td> <td>-9095.660</td> <td>-7557.413</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>number_stories</th>                          <td> 1.994e+04</td> <td>  388.346</td> <td>   51.335</td> <td> 0.000</td> <td> 1.92e+04</td> <td> 2.07e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>total_area</th>                              <td>    2.0949</td> <td>    0.108</td> <td>   19.339</td> <td> 0.000</td> <td>    1.883</td> <td>    2.307</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>total_livable_area</th>                      <td>   -0.5497</td> <td>    0.111</td> <td>   -4.950</td> <td> 0.000</td> <td>   -0.767</td> <td>   -0.332</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>year_built</th>                              <td>  359.5319</td> <td>   28.036</td> <td>   12.824</td> <td> 0.000</td> <td>  304.582</td> <td>  414.482</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>zip_code</th>                                <td>-1076.7367</td> <td>   49.340</td> <td>  -21.823</td> <td> 0.000</td> <td>-1173.442</td> <td> -980.031</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>lat</th>                                     <td> 2.115e+05</td> <td> 1.39e+04</td> <td>   15.210</td> <td> 0.000</td> <td> 1.84e+05</td> <td> 2.39e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>lng</th>                                     <td> 3.678e+05</td> <td> 2.19e+04</td> <td>   16.791</td> <td> 0.000</td> <td> 3.25e+05</td> <td> 4.11e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>sale_year</th>                               <td> 1.081e+04</td> <td>  259.208</td> <td>   41.694</td> <td> 0.000</td> <td> 1.03e+04</td> <td> 1.13e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>sale_month</th>                              <td> -819.1448</td> <td> 1016.591</td> <td>   -0.806</td> <td> 0.420</td> <td>-2811.642</td> <td> 1173.352</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>sale_week</th>                               <td>  785.0598</td> <td>  233.175</td> <td>    3.367</td> <td> 0.001</td> <td>  328.042</td> <td> 1242.078</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>sale_day</th>                                <td>  960.3489</td> <td>   85.510</td> <td>   11.231</td> <td> 0.000</td> <td>  792.750</td> <td> 1127.947</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>sale_dow</th>                                <td>-1475.6961</td> <td>  476.804</td> <td>   -3.095</td> <td> 0.002</td> <td>-2410.222</td> <td> -541.170</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>basements_full</th>                          <td> -2.19e+04</td> <td> 1894.880</td> <td>  -11.558</td> <td> 0.000</td> <td>-2.56e+04</td> <td>-1.82e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>basements_partial</th>                       <td> 6461.1330</td> <td> 2206.330</td> <td>    2.928</td> <td> 0.003</td> <td> 2136.770</td> <td> 1.08e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>category_code_description_Single Family</th> <td>-1.094e+05</td> <td> 2686.530</td> <td>  -40.713</td> <td> 0.000</td> <td>-1.15e+05</td> <td>-1.04e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>street_designation_DR</th>                   <td> 4.465e+04</td> <td> 7456.751</td> <td>    5.987</td> <td> 0.000</td> <td>    3e+04</td> <td> 5.93e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>street_designation_LA</th>                   <td> 2.323e+04</td> <td> 6248.288</td> <td>    3.719</td> <td> 0.000</td> <td>  1.1e+04</td> <td> 3.55e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>street_designation_Other</th>                <td> 1.657e+04</td> <td> 5674.728</td> <td>    2.920</td> <td> 0.003</td> <td> 5448.764</td> <td> 2.77e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>street_designation_PL</th>                   <td>  8.71e+04</td> <td> 7878.695</td> <td>   11.055</td> <td> 0.000</td> <td> 7.17e+04</td> <td> 1.03e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>street_designation_RD</th>                   <td> 2.214e+04</td> <td> 3949.111</td> <td>    5.606</td> <td> 0.000</td> <td> 1.44e+04</td> <td> 2.99e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>street_designation_SQ</th>                   <td> 2.006e+05</td> <td> 1.01e+04</td> <td>   19.809</td> <td> 0.000</td> <td> 1.81e+05</td> <td>  2.2e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>street_designation_ST</th>                   <td> 1678.6301</td> <td> 2192.763</td> <td>    0.766</td> <td> 0.444</td> <td>-2619.141</td> <td> 5976.401</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>topography_B</th>                            <td> 1.173e+05</td> <td> 3.59e+04</td> <td>    3.264</td> <td> 0.001</td> <td> 4.69e+04</td> <td> 1.88e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>topography_C</th>                            <td>-2.029e+04</td> <td> 4.53e+04</td> <td>   -0.448</td> <td> 0.654</td> <td>-1.09e+05</td> <td> 6.84e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>topography_D</th>                            <td>-9.043e+04</td> <td> 4.97e+04</td> <td>   -1.819</td> <td> 0.069</td> <td>-1.88e+05</td> <td> 7026.964</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>topography_E</th>                            <td>-1.008e+05</td> <td> 8244.408</td> <td>  -12.230</td> <td> 0.000</td> <td>-1.17e+05</td> <td>-8.47e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>topography_F</th>                            <td> -7.61e+04</td> <td> 2519.083</td> <td>  -30.208</td> <td> 0.000</td> <td> -8.1e+04</td> <td>-7.12e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>view_type_A</th>                             <td>-3386.0687</td> <td> 7742.524</td> <td>   -0.437</td> <td> 0.662</td> <td>-1.86e+04</td> <td> 1.18e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>view_type_B</th>                             <td> 9493.1211</td> <td> 1.26e+04</td> <td>    0.756</td> <td> 0.449</td> <td>-1.51e+04</td> <td> 3.41e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>view_type_C</th>                             <td> 1.375e+05</td> <td> 9014.554</td> <td>   15.253</td> <td> 0.000</td> <td>  1.2e+05</td> <td> 1.55e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>view_type_D</th>                             <td>-2.222e+04</td> <td> 1.24e+04</td> <td>   -1.798</td> <td> 0.072</td> <td>-4.64e+04</td> <td> 1996.486</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>view_type_E</th>                             <td>-2.076e+04</td> <td> 1.35e+04</td> <td>   -1.537</td> <td> 0.124</td> <td>-4.72e+04</td> <td> 5706.775</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>view_type_H</th>                             <td>-2.362e+04</td> <td> 1.22e+04</td> <td>   -1.933</td> <td> 0.053</td> <td>-4.76e+04</td> <td>  328.033</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>view_type_I</th>                             <td>-1.314e+04</td> <td> 6726.836</td> <td>   -1.954</td> <td> 0.051</td> <td>-2.63e+04</td> <td>   43.552</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>176059.597</td> <th>  Durbin-Watson:     </th>   <td>   1.175</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th>   <td> 0.000</td>   <th>  Jarque-Bera (JB):  </th> <td>96490665.060</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>            <td> 5.584</td>   <th>  Prob(JB):          </th>   <td>    0.00</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>        <td>126.503</td>  <th>  Cond. No.          </th>   <td>4.61e+07</td>  \n",
       "</tr>\n",
       "</table><br/><br/>Warnings:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The condition number is large, 4.61e+07. This might indicate that there are<br/>strong multicollinearity or other numerical problems."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                                 OLS Regression Results                                \n",
       "=======================================================================================\n",
       "Dep. Variable:             sale_price   R-squared (uncentered):                   0.511\n",
       "Model:                            OLS   Adj. R-squared (uncentered):              0.511\n",
       "Method:                 Least Squares   F-statistic:                              3347.\n",
       "Date:                Thu, 07 Apr 2022   Prob (F-statistic):                        0.00\n",
       "Time:                        02:25:03   Log-Likelihood:                     -2.1030e+06\n",
       "No. Observations:              150594   AIC:                                  4.206e+06\n",
       "Df Residuals:                  150547   BIC:                                  4.206e+06\n",
       "Df Model:                          47                                                  \n",
       "Covariance Type:            nonrobust                                                  \n",
       "===========================================================================================================\n",
       "                                              coef    std err          t      P>|t|      [0.025      0.975]\n",
       "-----------------------------------------------------------------------------------------------------------\n",
       "census_tract                             -542.0122     12.460    -43.501      0.000    -566.433    -517.591\n",
       "depth                                       2.2588      1.652      1.367      0.171      -0.979       5.496\n",
       "exterior_condition                       -1.33e+04   3855.868     -3.449      0.001   -2.09e+04   -5739.806\n",
       "fireplaces                               1.307e+05   2687.158     48.628      0.000    1.25e+05    1.36e+05\n",
       "frontage                                    0.3336      0.063      5.330      0.000       0.211       0.456\n",
       "garage_spaces                            2.035e+04    960.676     21.186      0.000    1.85e+04    2.22e+04\n",
       "geographic_ward                         -1241.4575     49.592    -25.034      0.000   -1338.656   -1144.259\n",
       "house_number                               -3.3164      0.256    -12.973      0.000      -3.818      -2.815\n",
       "interior_condition                      -4.874e+04   3831.887    -12.720      0.000   -5.63e+04   -4.12e+04\n",
       "market_value                                0.1034      0.001     78.353      0.000       0.101       0.106\n",
       "number_of_bathrooms                      3.125e+04   1270.482     24.599      0.000    2.88e+04    3.37e+04\n",
       "number_of_bedrooms                      -7195.0285    821.403     -8.759      0.000   -8804.962   -5585.095\n",
       "number_of_rooms                         -8326.5364    392.414    -21.219      0.000   -9095.660   -7557.413\n",
       "number_stories                           1.994e+04    388.346     51.335      0.000    1.92e+04    2.07e+04\n",
       "total_area                                  2.0949      0.108     19.339      0.000       1.883       2.307\n",
       "total_livable_area                         -0.5497      0.111     -4.950      0.000      -0.767      -0.332\n",
       "year_built                                359.5319     28.036     12.824      0.000     304.582     414.482\n",
       "zip_code                                -1076.7367     49.340    -21.823      0.000   -1173.442    -980.031\n",
       "lat                                      2.115e+05   1.39e+04     15.210      0.000    1.84e+05    2.39e+05\n",
       "lng                                      3.678e+05   2.19e+04     16.791      0.000    3.25e+05    4.11e+05\n",
       "sale_year                                1.081e+04    259.208     41.694      0.000    1.03e+04    1.13e+04\n",
       "sale_month                               -819.1448   1016.591     -0.806      0.420   -2811.642    1173.352\n",
       "sale_week                                 785.0598    233.175      3.367      0.001     328.042    1242.078\n",
       "sale_day                                  960.3489     85.510     11.231      0.000     792.750    1127.947\n",
       "sale_dow                                -1475.6961    476.804     -3.095      0.002   -2410.222    -541.170\n",
       "basements_full                           -2.19e+04   1894.880    -11.558      0.000   -2.56e+04   -1.82e+04\n",
       "basements_partial                        6461.1330   2206.330      2.928      0.003    2136.770    1.08e+04\n",
       "category_code_description_Single Family -1.094e+05   2686.530    -40.713      0.000   -1.15e+05   -1.04e+05\n",
       "street_designation_DR                    4.465e+04   7456.751      5.987      0.000       3e+04    5.93e+04\n",
       "street_designation_LA                    2.323e+04   6248.288      3.719      0.000     1.1e+04    3.55e+04\n",
       "street_designation_Other                 1.657e+04   5674.728      2.920      0.003    5448.764    2.77e+04\n",
       "street_designation_PL                     8.71e+04   7878.695     11.055      0.000    7.17e+04    1.03e+05\n",
       "street_designation_RD                    2.214e+04   3949.111      5.606      0.000    1.44e+04    2.99e+04\n",
       "street_designation_SQ                    2.006e+05   1.01e+04     19.809      0.000    1.81e+05     2.2e+05\n",
       "street_designation_ST                    1678.6301   2192.763      0.766      0.444   -2619.141    5976.401\n",
       "topography_B                             1.173e+05   3.59e+04      3.264      0.001    4.69e+04    1.88e+05\n",
       "topography_C                            -2.029e+04   4.53e+04     -0.448      0.654   -1.09e+05    6.84e+04\n",
       "topography_D                            -9.043e+04   4.97e+04     -1.819      0.069   -1.88e+05    7026.964\n",
       "topography_E                            -1.008e+05   8244.408    -12.230      0.000   -1.17e+05   -8.47e+04\n",
       "topography_F                             -7.61e+04   2519.083    -30.208      0.000    -8.1e+04   -7.12e+04\n",
       "view_type_A                             -3386.0687   7742.524     -0.437      0.662   -1.86e+04    1.18e+04\n",
       "view_type_B                              9493.1211   1.26e+04      0.756      0.449   -1.51e+04    3.41e+04\n",
       "view_type_C                              1.375e+05   9014.554     15.253      0.000     1.2e+05    1.55e+05\n",
       "view_type_D                             -2.222e+04   1.24e+04     -1.798      0.072   -4.64e+04    1996.486\n",
       "view_type_E                             -2.076e+04   1.35e+04     -1.537      0.124   -4.72e+04    5706.775\n",
       "view_type_H                             -2.362e+04   1.22e+04     -1.933      0.053   -4.76e+04     328.033\n",
       "view_type_I                             -1.314e+04   6726.836     -1.954      0.051   -2.63e+04      43.552\n",
       "==============================================================================\n",
       "Omnibus:                   176059.597   Durbin-Watson:                   1.175\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):         96490665.060\n",
       "Skew:                           5.584   Prob(JB):                         0.00\n",
       "Kurtosis:                     126.503   Cond. No.                     4.61e+07\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The condition number is large, 4.61e+07. This might indicate that there are\n",
       "strong multicollinearity or other numerical problems.\n",
       "\"\"\""
      ]
     },
     "execution_count": 341,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import statsmodels.api as sm\n",
    "model = sm.OLS(train['sale_price'], \n",
    "               train.drop(['sale_price'], axis=1)\n",
    "           )\n",
    "results = model.fit()\n",
    "results.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import xgboost as xgb\n",
    "from sklearn import tree\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# data_dmatrix = xgb.DMatrix(train.drop(['sale_price'], axis=1),\n",
    "#             train['sale_price'])\n",
    "\n",
    "# xg_reg = xgb.XGBRegressor(objective ='reg:linear', colsample_bytree = 0.3, learning_rate = 0.1,\n",
    "#                 max_depth = 5, alpha = 10, n_estimators = 10)\n",
    "# regr = RandomForestRegressor()\n",
    "# regr.fit(train.drop(['sale_price'], axis=1),\n",
    "#            train['sale_price'])\n",
    "\n",
    "# rfpreds = regr.predict(train.drop(['sale_price'], axis=1))\n",
    "# mean_squared_error(train['sale_price'], rfpreds)\n",
    "\n",
    "# xg_reg.fit(train.drop(['sale_price'], axis=1),\n",
    "#             train['sale_price'])\n",
    "\n",
    "# preds = xg_reg.predict(train.drop(['sale_price'], axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "cat_vars_test = test[['basements','category_code_description','street_designation',\n",
    "               'topography', 'view_type']]\n",
    "cat_dummies_test = pd.get_dummies(cat_vars_test, drop_first=True)\n",
    "\n",
    "test = test.drop(['basements','category_code_description','street_designation',\n",
    "               'topography', 'view_type'], axis=1)\n",
    "test = pd.concat([test, cat_dummies_test], axis=1)\n",
    "\n",
    "test = test.fillna(test.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "82704113290.46231"
      ]
     },
     "execution_count": 348,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rpreds = reg.predict(test.drop(['sale_price'], axis=1))\n",
    "mean_squared_error(test['sale_price'], rpreds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then pickle the dataset for later use and easy loading:    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle_out = open(\"housedat.pickle\",\"wb\")\n",
    "pickle.dump(dat, pickle_out)\n",
    "pickle_out.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "possible predictions datasets:   \n",
    "https://www.kaggle.com/datasets/harlfoxem/housesalesprediction     \n",
    "https://github.com/michellesklee/predicting_home_values    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
